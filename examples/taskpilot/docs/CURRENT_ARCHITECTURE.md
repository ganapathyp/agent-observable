# Current Architecture in Use

## Overview

This document shows the **actual architecture** currently implemented and running in your system.

---

## ğŸ—ï¸ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        TaskPilot System Architecture                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    Application Layer                               â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚ â”‚
â”‚  â”‚  â”‚         main.py (Dual Mode)              â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚                                           â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚  Script Mode: python main.py              â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚    - Runs workflow once                   â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚    - Exits                                 â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚                                           â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚  Server Mode: python main.py --server     â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚    - HTTP server on port 8000             â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚    - /metrics, /health, /golden-signals   â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚    - Workflow runs in background           â”‚                     â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚ â”‚
â”‚  â”‚                     â”‚                                               â”‚ â”‚
â”‚  â”‚                     â”‚ Writes/Reads                                  â”‚ â”‚
â”‚  â”‚                     â”‚                                               â”‚ â”‚
â”‚  â”‚                     â–¼                                               â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚ â”‚
â”‚  â”‚  â”‚         File-Based Storage                â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚                                            â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ metrics.json      (metrics data)       â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ traces.jsonl      (trace spans)        â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ decision_logs.jsonl (OPA/NeMo decisions)â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ logs/taskpilot.log (JSON logs)         â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ .tasks.json       (task store)         â”‚                     â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Observability Stack (Docker Compose)                  â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚ â”‚
â”‚  â”‚  â”‚  Prometheus  â”‚ â—„â”€â”€â”€ Scrapes â”€â”€â”€â”€ main.py:8000/metrics         â”‚ â”‚
â”‚  â”‚  â”‚  Port: 9090  â”‚                                                 â”‚ â”‚
â”‚  â”‚  â”‚  (Metrics)   â”‚                                                 â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚ â”‚
â”‚  â”‚         â”‚                                                          â”‚ â”‚
â”‚  â”‚         â–¼                                                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚ â”‚
â”‚  â”‚  â”‚   Grafana    â”‚ â—„â”€â”€â”€ Reads from Prometheus                      â”‚ â”‚
â”‚  â”‚  â”‚  Port: 3000  â”‚                                                 â”‚ â”‚
â”‚  â”‚  â”‚ (Dashboards) â”‚                                                 â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚ â”‚
â”‚  â”‚  â”‚ OpenTelemetryâ”‚ â—„â”€â”€â”€ Receives â”€â”€â”€â”€ main.py (OTLP gRPC)         â”‚ â”‚
â”‚  â”‚  â”‚  Collector   â”‚                                                 â”‚ â”‚
â”‚  â”‚  â”‚ Ports: 4317/8â”‚                                                 â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚ â”‚
â”‚  â”‚         â”‚                                                          â”‚ â”‚
â”‚  â”‚         â–¼                                                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚ â”‚
â”‚  â”‚  â”‚    Jaeger    â”‚ â—„â”€â”€â”€ Receives traces from OTel Collector        â”‚ â”‚
â”‚  â”‚  â”‚  Port: 16686 â”‚                                                 â”‚ â”‚
â”‚  â”‚  â”‚  (Traces UI) â”‚                                                 â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚ â”‚
â”‚  â”‚  â”‚  Filebeat    â”‚ â—„â”€â”€â”€ Reads â”€â”€â”€â”€ logs/taskpilot.log             â”‚ â”‚
â”‚  â”‚  â”‚  (Log Shipper)â”‚     (mounted volume)                            â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚ â”‚
â”‚  â”‚         â”‚                                                          â”‚ â”‚
â”‚  â”‚         â–¼                                                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚ â”‚
â”‚  â”‚  â”‚ Elasticsearchâ”‚ â—„â”€â”€â”€ Receives logs from Filebeat                â”‚ â”‚
â”‚  â”‚  â”‚  Port: 9200  â”‚                                                 â”‚ â”‚
â”‚  â”‚  â”‚  (Log Store) â”‚                                                 â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚ â”‚
â”‚  â”‚         â”‚                                                          â”‚ â”‚
â”‚  â”‚         â–¼                                                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚ â”‚
â”‚  â”‚  â”‚    Kibana    â”‚ â—„â”€â”€â”€ Reads from Elasticsearch                   â”‚ â”‚
â”‚  â”‚  â”‚  Port: 5601  â”‚                                                 â”‚ â”‚
â”‚  â”‚  â”‚  (Logs UI)   â”‚                                                 â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Component Details

### 1. Application Components

#### `main.py` (Main Application)

**Dual-Mode Application:**

**Script Mode (Default):**
```bash
python main.py
# Runs workflow once and exits
```

**Server Mode (Production):**
```bash
python main.py --server --port 8000
# Runs HTTP server + workflow in background
```

**Features:**
- âœ… Integrated HTTP server (FastAPI)
- âœ… Metrics endpoints (`/metrics`, `/health`, `/golden-signals`)
- âœ… Workflow execution in background (server mode)
- âœ… Automatic observability (metrics, traces, logs)

**Endpoints:**
- `GET /metrics` - Prometheus metrics (text/plain)
- `GET /health` - Health checks (JSON)
- `GET /golden-signals` - Golden Signals (JSON)
- `GET /` - Service info (JSON)

**Observability Integration:**
- Metrics: Automatic collection in middleware
- Traces: Automatic span creation and OpenTelemetry export
- Logs: JSON logging to `logs/taskpilot.log`

---

### 2. Observability Stack

#### Prometheus
- **Port**: 9090
- **Purpose**: Metrics collection and storage
- **Scrapes**: `host.docker.internal:8000/metrics` (when `main.py --server` is running)
- **Interval**: 15 seconds
- **Storage**: 30-day retention
- **Config**: `observability/prometheus/prometheus.yml`

**Metrics Available:**
- Workflow metrics: `workflow_runs`, `workflow_success`, `workflow_latency_ms`
- Agent metrics: `agent_*_invocations`, `agent_*_latency_ms`, `agent_*_errors`
- **Token metrics** (automatic tracking):
  - `llm_tokens_input_total` - Total input tokens across all models
  - `llm_tokens_output_total` - Total output tokens across all models
  - `llm_tokens_total_all` - Total tokens (input + output)
  - `llm_tokens_input_{model}` - Input tokens per model (e.g., `llm_tokens_input_gpt_4o`)
  - `llm_tokens_output_{model}` - Output tokens per model
  - `llm_tokens_total_{model}` - Total tokens per model
- **Cost metrics** (automatic calculation):
  - `llm_cost_total` - Total cost in USD
  - `llm_cost_agent_{agent_name}` - Cost per agent
  - `llm_cost_model_{model}` - Cost per model
- Task metrics: `tasks_created`, `tasks_approved`, `tasks_rejected`
- Policy metrics: `policy_violations_total`, `agent_{agent_name}_policy_violations`

**Token & Cost Tracking:**
- Automatically tracked in middleware for all agent executions
- Token usage extracted from LLM responses (OpenAI-style or agent framework)
- Cost calculated using model-specific pricing (per 1K tokens)
- Supports multiple models: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-4, gpt-3.5-turbo
- Implementation: `src/core/llm_cost_tracker.py`

#### Grafana
- **Port**: 3000
- **Purpose**: Metrics visualization
- **Data Source**: Prometheus
- **Login**: admin/admin
- **Dashboards**: Custom dashboards (Golden Signals, etc.)

#### OpenTelemetry Collector
- **Ports**: 4317 (gRPC), 4318 (HTTP)
- **Purpose**: Trace collection and processing
- **Receives**: OTLP traces from `main.py`
- **Exports**: To Jaeger via OTLP HTTP

#### Jaeger
- **Port**: 16686
- **Purpose**: Trace visualization
- **Receives**: Traces from OTel Collector
- **UI**: Web-based trace viewer

#### Elasticsearch
- **Port**: 9200
- **Purpose**: Log storage and indexing
- **Receives**: Logs from Filebeat
- **Index**: `taskpilot-logs-*`

#### Kibana
- **Port**: 5601
- **Purpose**: Log visualization
- **Data Source**: Elasticsearch
- **Index Pattern**: `taskpilot-logs-*`

#### Filebeat
- **Purpose**: Log shipping
- **Reads**: `./logs/taskpilot.log` (mounted as `/var/log/taskpilot/taskpilot.log` in container)
- **Sends**: To Elasticsearch
- **Format**: JSON logs

---

## ğŸ”„ Data Flow

### Metrics Flow

```
main.py --server:8000
  â”‚
  â”‚ (serves /metrics endpoint)
  â”‚ (writes to metrics.json for persistence)
  â–¼
/metrics endpoint (Prometheus format)
  â”‚
  â”‚ (scrapes every 15s)
  â–¼
Prometheus:9090
  â”‚
  â”‚ (queries)
  â–¼
Grafana:3000
```

### Traces Flow

```
main.py
  â”‚
  â”‚ (OTLP gRPC)
  â–¼
OpenTelemetry Collector:4317
  â”‚
  â”‚ (OTLP HTTP)
  â–¼
Jaeger:16686
  â”‚
  â”‚ (also writes to file)
  â–¼
traces.jsonl
```

### Logs Flow

```
main.py
  â”‚
  â”‚ (writes JSON logs)
  â–¼
logs/taskpilot.log
  â”‚
  â”‚ (reads via mounted volume)
  â–¼
Filebeat
  â”‚
  â”‚ (ships logs)
  â–¼
Elasticsearch:9200
  â”‚
  â”‚ (queries)
  â–¼
Kibana:5601
```

---

## ğŸ—‚ï¸ File Storage

### Local Files (Project Directory)

| File | Purpose | Format |
|------|---------|--------|
| `metrics.json` | Metrics data | JSON |
| `traces.jsonl` | Trace spans | JSONL (one per line) |
| `decision_logs.jsonl` | OPA/NeMo decisions | JSONL |
| `logs/taskpilot.log` | Application logs | JSON (one per line) |
| `.tasks.json` | Task store | JSON |

### Docker Mounted Files

All configuration files are mounted from the project's `observability/` folder:

| Path | Purpose | Used By |
|------|---------|---------|
| `./logs/` | Logs directory | Filebeat (mounted as `/var/log/taskpilot`) |
| `./observability/prometheus/prometheus.yml` | Prometheus config | Prometheus |
| `./observability/otel/collector-config.yml` | OTel config | OTel Collector |
| `./observability/filebeat/filebeat.yml` | Filebeat config | Filebeat |
| `./observability/grafana/provisioning/` | Grafana provisioning | Grafana |

---

## ğŸŒ Network Architecture

### Ports in Use

| Port | Service | Purpose |
|------|---------|---------|
| **8000** | main.py --server | Integrated metrics + workflows |
| **9090** | Prometheus | Metrics UI |
| **3000** | Grafana | Dashboards |
| **4317** | OTel Collector | OTLP gRPC |
| **4318** | OTel Collector | OTLP HTTP |
| **16686** | Jaeger | Trace UI |
| **9200** | Elasticsearch | Log storage API |
| **5601** | Kibana | Log UI |

### Network Connections

```
Host Machine
  â”‚
  â”œâ”€â”€â”€ main.py --server:8000
  â”‚    â”‚
  â”‚    â”œâ”€â”€â”€ /metrics â”€â”€â”€â”€â–º Prometheus:9090 (scrapes every 15s)
  â”‚    â”‚
  â”‚    â””â”€â”€â”€ OTLP gRPC â”€â”€â”€â”€â–º OTel Collector:4317
  â”‚
  â”œâ”€â”€â”€ main.py (script mode, writes files)
  â”‚    â””â”€â”€â”€ Writes: metrics.json, traces.jsonl, logs/taskpilot.log
  â”‚
  â”œâ”€â”€â”€ OTel Collector:4318 â”€â”€â”€â”€â–º Jaeger:16686 (OTLP HTTP)
  â”‚
  â””â”€â”€â”€ Filebeat â”€â”€â”€â”€â–º Elasticsearch:9200 (HTTP)
```

---

## ğŸ”§ Configuration

### Environment Variables

| Variable | Purpose | Default |
|----------|---------|---------|
| `OTEL_EXPORTER_OTLP_ENDPOINT` | OTel Collector endpoint | `http://localhost:4317` |
| `OTEL_ENABLED` | Enable OpenTelemetry | `true` |
| `PORT` | Main server port (when --server) | `8000` |
| `OPENAI_API_KEY` | OpenAI API key | Required |

### Docker Compose Services

```yaml
services:
  prometheus:    # Metrics collection
  grafana:      # Metrics visualization
  otel-collector: # Trace collection
  jaeger:       # Trace visualization
  elasticsearch: # Log storage
  kibana:       # Log visualization
  filebeat:     # Log shipping
```

---

## ğŸ“ˆ Current Status

### âœ… Working

- âœ… Metrics collection (Prometheus scraping main.py --server)
- âœ… Metrics visualization (Grafana)
- âœ… Trace collection (OpenTelemetry)
- âœ… Trace visualization (Jaeger)
- âœ… Log collection (Filebeat)
- âœ… Log storage (Elasticsearch)
- âœ… Log visualization (Kibana)
- âœ… Golden Signals endpoint

### âš ï¸ Limitations

- âœ… **Metrics integrated** into main app (port 8000 with --server flag)
- âš ï¸ **File-based persistence** (not database)
- âš ï¸ **Single instance** (no clustering)
- âš ï¸ **Local development** setup (not production-ready)

---

## ğŸš€ How to Run

### Start Observability Stack

```bash
docker-compose -f docker-compose.observability.yml up -d
```

### Start Application

**Option 1: Server Mode (Production)**
```bash
# Single process with integrated metrics
python main.py --server --port 8000
```

**Option 2: Script Mode (Development)**
```bash
# Run workflow once (backward compatible)
python main.py

# Or use separate metrics server (optional)
python main.py --server --port 8000  # Terminal 1
python main.py            # Terminal 2
```

### Access Dashboards

- **Grafana**: http://localhost:3000 (admin/admin)
- **Prometheus**: http://localhost:9090
- **Jaeger**: http://localhost:16686
- **Kibana**: http://localhost:5601
- **Metrics API**: http://localhost:8000/metrics (server mode)
- **Health**: http://localhost:8000/health (server mode)
- **Golden Signals**: http://localhost:8000/golden-signals (server mode)
- **Integrated Metrics Server**: http://localhost:8000/metrics (when running with --server)

---

## ğŸ” Key Characteristics

### Architecture Style
- **Microservices**: Separate metrics server
- **File-based**: Local file persistence
- **Docker Compose**: All observability tools in containers
- **Hybrid**: Application runs on host, observability in Docker

### Data Persistence
- **Metrics**: `metrics.json` (file) + Prometheus (time-series DB)
- **Traces**: `traces.jsonl` (file) + Jaeger (in-memory)
- **Logs**: `logs/taskpilot.log` (file) + Elasticsearch (search DB)
- **Decisions**: `decision_logs.jsonl` (file)
- **Tasks**: `.tasks.json` (file)

### Scalability
- **Current**: Single instance
- **Limitation**: File-based storage (not shared)
- **Production**: Would need database/object storage

---

## ğŸ“ Summary

**Current Architecture:**
- âœ… **Application**: Python script (`main.py`) + separate metrics server
- âœ… **Observability**: Full stack (Prometheus, Grafana, Jaeger, ELK)
- âœ… **Storage**: File-based (local development)
- âœ… **Network**: Host + Docker containers
- âš ï¸ **Production Gap**: Metrics server not integrated into main app

**Key Insight:**
The system uses a **hybrid architecture**:
- Application runs on host (Python)
- Observability runs in Docker
- Communication via file I/O and network (OTLP, HTTP)

**Production Ready:**
- âœ… Metrics server integrated into main app
- âœ… Dual mode: Script mode (dev) + Server mode (prod)
- âœ… Backward compatible with existing setup
- âœ… Single container deployment ready
